import os
import sys
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.applications import EfficientNetV2M
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from datetime import datetime

# --------------------------------------------------
# 1ï¸âƒ£ í˜„ì¬ ì‹¤í–‰ íŒŒì¼ëª… ë¡œê·¸ ì¶œë ¥
# --------------------------------------------------
script_name = os.path.basename(sys.argv[0])
print(f"\nğŸš€ Running training script: {script_name}\n")

# --------------------------------------------------
# 2ï¸âƒ£ ë°ì´í„° ê²½ë¡œ ì„¤ì •
# --------------------------------------------------
DATASET_PATH = "dataset_2000"
TRAIN_PATH = os.path.join(DATASET_PATH, "train")
VAL_PATH = os.path.join(DATASET_PATH, "val")
TEST_PATH = os.path.join(DATASET_PATH, "test")

# --------------------------------------------------
# 3ï¸âƒ£ ë°ì´í„°ì…‹ ë¡œë“œ
# --------------------------------------------------
BATCH_SIZE = 32
IMG_SIZE = (224, 224)

train_ds = image_dataset_from_directory(
    TRAIN_PATH, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=True
)
val_ds = image_dataset_from_directory(
    VAL_PATH, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False
)
test_ds = image_dataset_from_directory(
    TEST_PATH, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False
)

# --------------------------------------------------
# 4ï¸âƒ£ í´ë˜ìŠ¤ ì´ë¦„ ì €ì¥ (Djangoìš© ë“±ì—ì„œ ì‚¬ìš©)
# --------------------------------------------------
class_names = train_ds.class_names
with open("class_names.txt", "w", encoding="utf-8") as f:
    for name in class_names:
        f.write(name + "\n")
print("âœ… Class names saved to class_names.txt")

# --------------------------------------------------
# 5ï¸âƒ£ Prefetch ìµœì í™”
# --------------------------------------------------
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)

# --------------------------------------------------
# 6ï¸âƒ£ ëª¨ë¸ êµ¬ì„± (EfficientNetV2M)
# --------------------------------------------------
base_model = EfficientNetV2M(include_top=False, input_shape=IMG_SIZE + (3,), weights="imagenet")
base_model.trainable = False

inputs = layers.Input(shape=IMG_SIZE + (3,))
x = base_model(inputs, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(len(class_names), activation="softmax")(x)
model = models.Model(inputs, outputs)

# --------------------------------------------------
# 7ï¸âƒ£ ì»´íŒŒì¼
# --------------------------------------------------
model.compile(
    optimizer=Adam(learning_rate=1e-4),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

# --------------------------------------------------
# 8ï¸âƒ£ ì½œë°± ì„¤ì •
# --------------------------------------------------
MODEL_SAVE_PATH = "trained_model_EffNetV2M_v3.0.keras"
checkpoint = ModelCheckpoint(
    MODEL_SAVE_PATH, monitor="val_accuracy", save_best_only=True, verbose=1
)
earlystop = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

# --------------------------------------------------
# 9ï¸âƒ£ í•™ìŠµ ì‹¤í–‰
# --------------------------------------------------
print("ğŸš€ Start training EfficientNetV2M ...")
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=50,
    callbacks=[checkpoint, earlystop],
    verbose=1,
)

# --------------------------------------------------
# ğŸ”Ÿ ìµœì¢… ì €ì¥ (keras í¬ë§·)
# --------------------------------------------------
model.save(MODEL_SAVE_PATH)
print(f"âœ… Model saved as: {MODEL_SAVE_PATH}")

# --------------------------------------------------
# 11ï¸âƒ£ í…ŒìŠ¤íŠ¸ í‰ê°€
# --------------------------------------------------
test_loss, test_acc = model.evaluate(test_ds)
print(f"âœ… Test Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}")
