import os
import json
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# 1. ë°ì´í„° ì¤€ë¹„ ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
import prepare_data 

# ===== ì„¤ì • =====
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 50           # ìµœëŒ€ 50 ì—í¬í¬ê¹Œì§€ í›ˆë ¨

ORIGINAL_DATA_DIR = "dataset/train"
SPLIT_DATA_DIR = "split_dataset"

# 2. ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜ í˜¸ì¶œ
DATA_DIR = prepare_data.prepare_and_split_data(
    input_dir=ORIGINAL_DATA_DIR,  # ì¸ìëª… ì†Œë¬¸ìë¡œ í†µì¼
    output_dir=SPLIT_DATA_DIR,    # ì¸ìëª… ì†Œë¬¸ìë¡œ í†µì¼
    ratio=(0.8, 0.2, 0.0)
)

# ğŸš¨ None ê²€ì‚¬ ë° ì¢…ë£Œ: DATA_DIRì´ Noneì´ë©´ ë°ì´í„° ë¡œë“œ ì „ ì¢…ë£Œ
if DATA_DIR is None:
    print("\nğŸš¨ ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆê±°ë‚˜ ì›ë³¸ ì´ë¯¸ì§€('dataset/train')ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

MODEL_DIR = "saved_model_recycle"

# ì¡°ê¸° ì¢…ë£Œ(Early Stopping) ì„¤ì •
EARLY_STOP_PATIENCE = 10 
MONITOR_METRIC = "val_loss" 

# ===== ë°ì´í„° ì œë„ˆë ˆì´í„° (ì´ë¯¸ì§€ ì¦ê°• ë° ì „ì²˜ë¦¬) =====
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator(rescale=1./255)

# í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„° ë¡œë“œ
try:
    train_gen = train_datagen.flow_from_directory(
        os.path.join(DATA_DIR, "train"),
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode="categorical",
        shuffle=True
    )
    val_gen = val_datagen.flow_from_directory(
        os.path.join(DATA_DIR, "val"),
        target_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        class_mode="categorical",
        shuffle=False
    )
except Exception as e:
    print(f"\n ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. '{DATA_DIR}' í´ë”ì— 'train'ê³¼ 'val'ì´ ì˜¬ë°”ë¥´ê²Œ ë¶„ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print(f"   ì˜¤ë¥˜: {e}")
    exit()

num_classes = len(train_gen.class_indices)
print(f"\n ê°ì§€ëœ í´ë˜ìŠ¤ ìˆ˜: {num_classes}ê°œ")

# ===== ëª¨ë¸ êµ¬ì„± (ì „ì´í•™ìŠµ: MobileNetV2) =====
base_model = tf.keras.applications.MobileNetV2(
    input_shape=(*IMG_SIZE, 3),
    include_top=False, 
    weights="imagenet", 
    pooling="avg" 
)
base_model.trainable = False 

inputs = layers.Input(shape=(*IMG_SIZE, 3))
x = base_model(inputs, training=False)
x = layers.Dropout(0.4)(x) 
x = layers.Dense(512, activation="relu")(x) 
x = layers.BatchNormalization()(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)

model = models.Model(inputs, outputs)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), 
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)

# ===== ì½œë°± (í•™ìŠµ ì œì–´) =====
os.makedirs(MODEL_DIR, exist_ok=True)

checkpoint = callbacks.ModelCheckpoint(
    filepath=os.path.join(MODEL_DIR, "best_model.h5"),
    monitor="val_accuracy",
    save_best_only=True,
    verbose=1
)
earlystop = callbacks.EarlyStopping(
    monitor=MONITOR_METRIC, 
    patience=EARLY_STOP_PATIENCE,
    restore_best_weights=True,
    verbose=1
)

# ===== í•™ìŠµ ì‹œì‘ =====
print("\n ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=EPOCHS,
    callbacks=[checkpoint, earlystop],
    steps_per_epoch=train_gen.samples // BATCH_SIZE, 
    validation_steps=val_gen.samples // BATCH_SIZE
)

# ===== ëª¨ë¸ ë° í´ë˜ìŠ¤ ì •ë³´ ì €ì¥ =====
model.save(os.path.join(MODEL_DIR, "final_saved_model"))
with open(os.path.join(MODEL_DIR, "class_indices.json"), "w") as f:
    json.dump(train_gen.class_indices, f)

print(f"\n í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ë° í´ë˜ìŠ¤ ì •ë³´ê°€ ì €ì¥ë¨: {MODEL_DIR}")