import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback

# ============================================================
# 0. CPU ì„¤ì • (M1/M2 Mac ì•ˆì •í™”)
# ============================================================
USE_GPU = False  # CPUë§Œ ì‚¬ìš©
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
print("CPU ëª¨ë“œë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")

# ============================================================
# 1. í™˜ê²½ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ============================================================
IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
DATASET_PATH = 'trash_dataset_path'
MODEL_NAME = 'trash_classifier_vgg16'

LEARNING_RATE_STEP1 = 1e-3
LEARNING_RATE_STEP2 = 1e-5

# ============================================================
# 2. ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬
# ============================================================
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest',
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input
)

val_test_datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.vgg16.preprocess_input
)

train_generator = train_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, 'train'),
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

validation_generator = val_test_datagen.flow_from_directory(
    os.path.join(DATASET_PATH, 'val'),
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

class_names = list(train_generator.class_indices.keys())
NUM_CLASSES = len(class_names)
print(f"ì´ í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}, í´ë˜ìŠ¤ ì´ë¦„: {class_names}")

# ============================================================
# 3. ëª¨ë¸ êµ¬ì¶• (VGG16)
# ============================================================
def build_vgg16_model(input_shape, num_classes):
    base_model = VGG16(
        input_shape=input_shape,
        include_top=False,
        weights='imagenet'
    )
    base_model.trainable = False  # Step1: Head Layerë§Œ í•™ìŠµ

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.3)(x)
    predictions = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    return model, base_model

model, base_model = build_vgg16_model(IMAGE_SIZE + (3,), NUM_CLASSES)
# model.summary()

# ============================================================
# 4. ì»¤ìŠ¤í…€ ì½œë°±: ì—°ì† ë°˜ë³µ ì •í™•ë„ ë³€í™” ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
# ============================================================
class RepeatEarlyStopping(Callback):
    def __init__(self, monitor='val_accuracy', patience=3):
        super().__init__()
        self.monitor = monitor
        self.patience = patience
        self.wait = 0
        self.prev_value = None

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get(self.monitor)
        if self.prev_value is not None and current == self.prev_value:
            self.wait += 1
            if self.wait >= self.patience:
                print(f"\nğŸ”¹ {self.monitor} ê°’ì´ {self.patience}ë²ˆ ì—°ì† ë³€í™” ì—†ìœ¼ë¯€ë¡œ í•™ìŠµ ì¢…ë£Œ")
                self.model.stop_training = True
        else:
            self.wait = 0
        self.prev_value = current

# ============================================================
# 5. í•™ìŠµ ì ˆì°¨
# ============================================================

# ---------------- Step1: Head Layer í•™ìŠµ ----------------
callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    RepeatEarlyStopping(monitor='val_accuracy', patience=3),  # ì¶”ê°€
    ModelCheckpoint(f'{MODEL_NAME}_best_step1.keras', monitor='val_accuracy', save_best_only=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)
]

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STEP1, amsgrad=False),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

history_step1 = model.fit(
    train_generator,
    epochs=1,
    validation_data=validation_generator,
    callbacks=callbacks
)

model.load_weights(f'{MODEL_NAME}_best_step1.keras')

# ---------------- Step2: Fine-tuning ----------------
num_layers_to_train = int(len(base_model.layers) * 0.3)
for layer in base_model.layers[-num_layers_to_train:]:
    if not isinstance(layer, tf.keras.layers.BatchNormalization):
        layer.trainable = True

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_STEP2, amsgrad=False),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

callbacks_ft = [
    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
    RepeatEarlyStopping(monitor='val_accuracy', patience=3),  # ì¶”ê°€
    ModelCheckpoint(f'{MODEL_NAME}_best_final.keras', monitor='val_accuracy', save_best_only=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, min_lr=1e-7, verbose=1)
]

history_step2 = model.fit(
    train_generator,
    epochs=1,
    validation_data=validation_generator,
    callbacks=callbacks_ft
)

model.load_weights(f'{MODEL_NAME}_best_final.keras')
print(f"\n ìµœì¢… ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ '{MODEL_NAME}_best_final.keras'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ============================================================
# 6. Inference ë° ë¶„ë¦¬ìˆ˜ê±° ê°€ì´ë“œ
# ============================================================
def predict_trash_type(model, image_path, class_names, threshold=0.9):
    img = tf.keras.utils.load_img(image_path, target_size=IMAGE_SIZE)
    img_array = tf.keras.utils.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    preprocessed_img = tf.keras.applications.vgg16.preprocess_input(img_array)

    predictions = model.predict(preprocessed_img, verbose=0)[0]
    max_prob = np.max(predictions)
    predicted_index = np.argmax(predictions)
    predicted_class = class_names[predicted_index]

    if max_prob >= threshold:
        result_message = f"[í™•ì •]: {predicted_class}ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤."
        confidence_level = "ë†’ìŒ"
    else:
        result_message = f"[ë¶ˆí™•ì‹¤]: {predicted_class}ë¡œ ì˜ˆì¸¡ë˜ì§€ë§Œ, ì‹ ë¢°ë„({max_prob*100:.2f}%)ê°€ ë‚®ì•„ ì¬í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."
        confidence_level = "ë‚®ìŒ"

    top_3_indices = np.argsort(predictions)[::-1][:3]
    top_3_results = [f"{class_names[i]} ({predictions[i]*100:.2f}%)" for i in top_3_indices]

    return predicted_class, max_prob, result_message, confidence_level, top_3_results

TRASH_GUIDE_MAP = {
    'steel_can1': {'category': 'ìº”ë¥˜', 'action': 'ë‚´ìš©ë¬¼ ë¹„ìš°ê³  ì••ì°© í›„ ë°°ì¶œ'},
    'aluminum_can1': {'category': 'ìº”ë¥˜', 'action': 'ë‚´ìš©ë¬¼ ë¹„ìš°ê³  ì••ì°© í›„ ë°°ì¶œ'},
    'paper1': {'category': 'ì¢…ì´ë¥˜', 'action': 'ë¬¼ê¸°ì— ì –ì§€ ì•Šë„ë¡ í´ì„œ ë¬¶ì–´ ë°°ì¶œ'},
    'pet_clear_single1': {'category': 'í”Œë¼ìŠ¤í‹±', 'action': 'ë‚´ìš©ë¬¼ ë¹„ìš°ê³  ë¼ë²¨ ì œê±° í›„ ì••ì°© ë°°ì¶œ'},
    'battery': {'category': 'íŠ¹ìˆ˜ íê¸°ë¬¼', 'action': 'íê±´ì „ì§€ ìˆ˜ê±°í•¨ì— ë°°ì¶œ (ë¶„ë¦¬ìˆ˜ê±° ì•„ë‹˜)'},
    'fluorescent_lamp': {'category': 'íŠ¹ìˆ˜ íê¸°ë¬¼', 'action': 'ì „ìš© ìˆ˜ê±°í•¨ì— ë°°ì¶œ (ë¶„ë¦¬ìˆ˜ê±° ì•„ë‹˜)'},
}

def get_recycling_guidance(predicted_class, mapping_table):
    if predicted_class in mapping_table:
        guide = mapping_table[predicted_class]
        return f"ë¶„ë¦¬ìˆ˜ê±° ì¹´í…Œê³ ë¦¬: {guide['category']}, ë°°ì¶œ ë°©ë²•: {guide['action']}"
    return "í•´ë‹¹ ì“°ë ˆê¸°ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ë¶„ë¦¬ìˆ˜ê±° ê°€ì´ë“œê°€ ì—†ìŠµë‹ˆë‹¤."
