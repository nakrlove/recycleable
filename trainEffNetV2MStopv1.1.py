# =====================================
# ğŸ§  Colab ì„¸ì…˜ ìœ ì§€ ì½”ë“œ (ì—…ê·¸ë ˆì´ë“œ ë²„ì „)
# =====================================
from IPython.display import Javascript, display

def keep_colab_alive(interval_min=15):
    js_code = f"""
    async function ClickConnect() {{
        console.log("[KeepAlive] Colab ì„¸ì…˜ ìœ ì§€ ì¤‘...");
        const btn = document.querySelector("colab-connect-button") 
                 || document.querySelector("#connect") 
                 || document.querySelector("colab-toolbar-button#connect") 
                 || document.querySelector("colab-sessions-button") 
                 || document.querySelector("#top-toolbar colab-connect-button");
        if (btn) {{
            btn.click();
            console.log("âœ… ì—°ê²° ìœ ì§€ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ");
        }} else {{
            console.log("âš ï¸ Colab ì—°ê²° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (UI ë³€ê²½ ê°€ëŠ¥ì„±)");
        }}
    }}
    setInterval(ClickConnect, {interval_min} * 60 * 1000);
    console.log("âœ… Colab Keep-Alive í™œì„±í™”ë¨ â€” {interval_min}ë¶„ ê°„ê²©ìœ¼ë¡œ í´ë¦­ ì¤‘");
    """
    try:
        display(Javascript(js_code))
    except Exception as e:
        print("âš ï¸ Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. ì„¸ì…˜ ìœ ì§€ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤.")
        print(e)

keep_colab_alive(30)



import os
import shutil
import random
from pathlib import Path
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetV2M
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ============================================================
# 1ï¸âƒ£ ê²½ë¡œ ì„¤ì • (Google Drive ê¸°ì¤€)
# ============================================================
ROOT = Path("drive/MyDrive")
BASE_DIR = ROOT / "dataset_sp"
TRAIN_DIR = BASE_DIR / "train"
VAL_DIR = BASE_DIR / "val"
TEST_DIR = BASE_DIR / "test"

IMAGE_SIZE = (224, 224)
BATCH_SIZE = 32
EPOCHS = 20
MODEL_SAVE_PATH = ROOT / "recycle_classifier_v2m_fixed.keras"

# ============================================================
# 2ï¸âƒ£ val/test í´ë” ìƒì„± ë° trainì—ì„œ ìë™ ë¶„í•  (8:1:1)
# ============================================================
def split_train_val_test(train_dir, val_dir, test_dir, val_ratio=0.1, test_ratio=0.1):
    val_dir.mkdir(parents=True, exist_ok=True)
    test_dir.mkdir(parents=True, exist_ok=True)

    for cls in os.listdir(train_dir):
        class_train_path = train_dir / cls
        if not class_train_path.is_dir():
            continue
        images = [f for f in os.listdir(class_train_path) if f.lower().endswith((".jpg",".png"))]
        random.shuffle(images)

        n_total = len(images)
        n_val = max(1, int(n_total * val_ratio))
        n_test = max(1, int(n_total * test_ratio))
        n_train = n_total - n_val - n_test

        val_cls_dir = val_dir / cls
        test_cls_dir = test_dir / cls
        val_cls_dir.mkdir(exist_ok=True)
        test_cls_dir.mkdir(exist_ok=True)

        # val/testì—ë§Œ ë³µì‚¬
        for f in images[n_train:n_train+n_val]:
            shutil.copy(class_train_path / f, val_cls_dir / f)
        for f in images[n_train+n_val:]:
            shutil.copy(class_train_path / f, test_cls_dir / f)

split_train_val_test(TRAIN_DIR, VAL_DIR, TEST_DIR)

# ============================================================
# 3ï¸âƒ£ ë°ì´í„° ì œë„ˆë ˆì´í„°
# ============================================================
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True,
    seed=42
)
val_generator = val_test_datagen.flow_from_directory(
    VAL_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)
test_generator = val_test_datagen.flow_from_directory(
    TEST_DIR,
    target_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

NUM_CLASSES = len(train_generator.class_indices)
print(f"í´ë˜ìŠ¤ ìˆ˜: {NUM_CLASSES}, í´ë˜ìŠ¤ ëª©ë¡: {list(train_generator.class_indices.keys())}")

steps_per_epoch = max(1, train_generator.samples // BATCH_SIZE)
validation_steps = max(1, val_generator.samples // BATCH_SIZE)

# ============================================================
# 4ï¸âƒ£ ëª¨ë¸ êµ¬ì„± (EfficientNetV2M)
# ============================================================
base_model = EfficientNetV2M(weights="imagenet", include_top=False, input_shape=(*IMAGE_SIZE,3))
base_model.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
output = Dense(NUM_CLASSES, activation="softmax")(x)
model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer=Adam(1e-3), loss="categorical_crossentropy", metrics=["accuracy"])
model.summary()

# ============================================================
# 5ï¸âƒ£ ì½œë°±
# ============================================================
callbacks = [
    ModelCheckpoint(MODEL_SAVE_PATH, monitor="val_accuracy", save_best_only=True, mode="max"),
    ReduceLROnPlateau(monitor="val_loss", factor=0.1, patience=3, verbose=1),
    EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
]

# ============================================================
# 6ï¸âƒ£ Stage 1: Feature extractor í•™ìŠµ
# ============================================================
history1 = model.fit(
    train_generator,
    epochs=EPOCHS//2,
    validation_data=val_generator,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=callbacks
)

# ============================================================
# 7ï¸âƒ£ Stage 2: Fine-tuning
# ============================================================
base_model.trainable = True
for layer in base_model.layers[:-50]:
    layer.trainable = False

model.compile(optimizer=Adam(1e-4), loss="categorical_crossentropy", metrics=["accuracy"])

history2 = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=val_generator,
    steps_per_epoch=steps_per_epoch,
    validation_steps=validation_steps,
    callbacks=callbacks
)

# ============================================================
# 8ï¸âƒ£ í…ŒìŠ¤íŠ¸ í‰ê°€
# ============================================================
loss, acc = model.evaluate(test_generator)
print(f"ìµœì¢… í…ŒìŠ¤íŠ¸ ì •í™•ë„: {acc:.4f}")


# ================================
# ë¶„ë¥˜ í•¨ìˆ˜
# ================================
# def classify_image(model, image_path, threshold=0.5):
#     img = tf.io.read_file(image_path)
#     img = tf.image.decode_jpeg(img, channels=3)
#     img = tf.cast(img, tf.float32) / 255.0
#     img = tf.expand_dims(img, axis=0)

#     preds = model.predict(img)
#     class_id = np.argmax(preds[0])
#     confidence = preds[0][class_id]

#     if confidence < threshold:
#         return "ì¼ë°˜ì“°ë ˆê¸°"
#     else:
#         return classes[class_id]

def classify_image(model, image_path, classes, threshold=0.5):
    """
    í•™ìŠµìš© ì½”ë“œ(ì˜µì…˜1) ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì´ë¯¸ì§€ ë¶„ë¥˜
    Args:
        model: í•™ìŠµëœ Keras ëª¨ë¸
        image_path: ë¶„ë¥˜í•  ì´ë¯¸ì§€ ê²½ë¡œ
        classes: í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
        threshold: confidence ì„ê³„ê°’
    Returns:
        class_name ë˜ëŠ” "ì¼ë°˜ì“°ë ˆê¸°"
    """
    # ì´ë¯¸ì§€ ì½ê¸° ë° ë””ì½”ë”© (JPEG, PNG ëª¨ë‘ ê°€ëŠ¥)
    img = tf.io.read_file(image_path)
    img = tf.image.decode_image(img, channels=3)
    
    # í•™ìŠµìš© ì½”ë“œ ê¸°ì¤€: ì´ë¯¸ 224x224ì´ë¯€ë¡œ resize ë¶ˆí•„ìš”
    img.set_shape([224, 224, 3])
    
    # ì •ê·œí™”
    img = tf.cast(img, tf.float32) / 255.0
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    img = tf.expand_dims(img, axis=0)
    
    # ì˜ˆì¸¡
    preds = model.predict(img)
    class_id = np.argmax(preds[0])
    confidence = preds[0][class_id]
    
    # threshold ê¸°ì¤€ íŒì •
    if confidence < threshold:
        return "ì¼ë°˜ì“°ë ˆê¸°"
    else:
        return classes[class_id], float(confidence)

# ì˜ˆì‹œ
# result = classify_image(model, "sample.jpg")
# print("ë¶„ë¥˜ ê²°ê³¼:", result)
