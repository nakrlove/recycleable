# =====================================
# ğŸ§  Colab ì„¸ì…˜ ìœ ì§€ ì½”ë“œ (ì—…ê·¸ë ˆì´ë“œ ë²„ì „)
# =====================================
from IPython.display import Javascript, display

def keep_colab_alive(interval_min=15):
    js_code = f"""
    async function ClickConnect() {{
        console.log("[KeepAlive] Colab ì„¸ì…˜ ìœ ì§€ ì¤‘...");
        const btn = document.querySelector("colab-connect-button") 
                 || document.querySelector("#connect") 
                 || document.querySelector("colab-toolbar-button#connect") 
                 || document.querySelector("colab-sessions-button") 
                 || document.querySelector("#top-toolbar colab-connect-button");
        if (btn) {{
            btn.click();
            console.log("âœ… ì—°ê²° ìœ ì§€ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ");
        }} else {{
            console.log("âš ï¸ Colab ì—°ê²° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (UI ë³€ê²½ ê°€ëŠ¥ì„±)");
        }}
    }}
    setInterval(ClickConnect, {interval_min} * 60 * 1000);
    console.log("âœ… Colab Keep-Alive í™œì„±í™”ë¨ â€” {interval_min}ë¶„ ê°„ê²©ìœ¼ë¡œ í´ë¦­ ì¤‘");
    """
    try:
        display(Javascript(js_code))
    except Exception as e:
        print("âš ï¸ Colab í™˜ê²½ì´ ì•„ë‹™ë‹ˆë‹¤. ì„¸ì…˜ ìœ ì§€ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¬´ì‹œë©ë‹ˆë‹¤.")
        print(e)

keep_colab_alive(30)

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetV2M
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt

# ================================
# ì„¤ì •
# ================================
split_dir = "dataset_split"  # train/val/test í¬í•¨ í´ë”
img_size = (224, 224)        # ì´ë¯¸ 224x224ë¼ resize ë¶ˆí•„ìš”
batch_size = 32
epochs = 25
model_save_path = "recycle_classifier_v2m_finetuned.keras"

# ================================
# ë°ì´í„° ë””ë ‰í† ë¦¬
# ================================
train_dir = Path(split_dir) / "train"
val_dir   = Path(split_dir) / "val"
test_dir  = Path(split_dir) / "test"

# ================================
# í´ë˜ìŠ¤ íƒìƒ‰
# ================================
classes = [d.name for d in train_dir.iterdir() if d.is_dir()]
class_indices = {cls: i for i, cls in enumerate(classes)}

# ================================
# í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
# ================================
class_files = {}
for cls in classes:
    files = list((train_dir / cls).glob("*"))
    class_files[cls] = [str(f) for f in files]

num_classes = len(classes)
max_count = max(len(v) for v in class_files.values())

# ================================
# í•™ìŠµ ì‹œì  oversampling (tf.data)
# ================================
AUTOTUNE = tf.data.AUTOTUNE

def preprocess_image(file_path, label):
    # ì´ë¯¸ 224x224ë¡œ ë˜ì–´ ìˆì–´ resize/ì „ì²˜ë¦¬ ì œê±°
    img = tf.io.read_file(file_path)
    img = tf.image.decode_image(img, channels=3)
    img.set_shape([224, 224, 3])
    img = tf.cast(img, tf.float32) / 255.0
    return img, label

per_class_datasets = []
for i, cls in enumerate(classes):
    paths = class_files[cls]
    ds = tf.data.Dataset.from_tensor_slices((paths, [i]*len(paths)))
    ds = ds.shuffle(len(paths)).repeat() \
           .map(preprocess_image, num_parallel_calls=AUTOTUNE)
    per_class_datasets.append(ds)

# sample_from_datasetsë¡œ ê· í˜• ìƒ˜í”Œë§
train_ds = tf.data.experimental.sample_from_datasets(per_class_datasets, weights=[1/num_classes]*num_classes)
train_ds = train_ds.batch(batch_size).prefetch(AUTOTUNE)

# ================================
# validation/test dataset (deterministic)
# ================================
def make_eval_ds(dir_path):
    images, labels = [], []
    for i, cls in enumerate(classes):
        for p in (dir_path / cls).glob("*"):
            images.append(str(p))
            labels.append(i)
    ds = tf.data.Dataset.from_tensor_slices((images, labels))
    ds = ds.map(preprocess_image, num_parallel_calls=AUTOTUNE)
    return ds.batch(batch_size).prefetch(AUTOTUNE)

val_ds = make_eval_ds(val_dir)
test_ds = make_eval_ds(test_dir)

# ================================
# ëª¨ë¸ êµ¬ì„±
# ================================
base_model = EfficientNetV2M(weights="imagenet", include_top=False, input_shape=(224,224,3))
base_model.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
output = Dense(num_classes, activation="softmax")(x)
model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer=Adam(1e-3), loss="sparse_categorical_crossentropy", metrics=["accuracy"])

# ================================
# ì½œë°±
# ================================
callbacks = [
    EarlyStopping(monitor="val_accuracy", patience=5, restore_best_weights=True),
    ModelCheckpoint(model_save_path, monitor="val_accuracy", save_best_only=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.3, patience=3, min_lr=1e-6)
]

# ================================
# 1ë‹¨ê³„: Feature Extractor í•™ìŠµ
# ================================
history_stage1 = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=10,
    steps_per_epoch=(max_count*num_classes)//batch_size,
    callbacks=callbacks
)

# ================================
# 2ë‹¨ê³„: Fine-Tuning
# ================================
for layer in base_model.layers[-40:]:
    layer.trainable = True

model.compile(optimizer=Adam(1e-5), loss="sparse_categorical_crossentropy", metrics=["accuracy"])

history_stage2 = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs,
    steps_per_epoch=(max_count*num_classes)//batch_size,
    callbacks=callbacks
)

# ================================
# í•™ìŠµ ê²°ê³¼ ì‹œê°í™”
# ================================
def plot_history(hist1, hist2):
    acc = hist1.history["accuracy"] + hist2.history["accuracy"]
    val_acc = hist1.history["val_accuracy"] + hist2.history["val_accuracy"]
    loss = hist1.history["loss"] + hist2.history["loss"]
    val_loss = hist1.history["val_loss"] + hist2.history["val_loss"]

    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.plot(acc, label="train_acc")
    plt.plot(val_acc, label="val_acc")
    plt.title("Accuracy")
    plt.legend()
    plt.subplot(1,2,2)
    plt.plot(loss, label="train_loss")
    plt.plot(val_loss, label="val_loss")
    plt.title("Loss")
    plt.legend()
    plt.show()

plot_history(history_stage1, history_stage2)

# ================================
# ëª¨ë¸ ì €ì¥
# ================================
model.save(model_save_path, save_format="keras")
print("âœ… Fine-Tuned ëª¨ë¸ ì €ì¥ ì™„ë£Œ:", model_save_path)


# ================================
# ë¶„ë¥˜ í•¨ìˆ˜
# ================================
# def classify_image(model, image_path, threshold=0.5):
#     img = tf.io.read_file(image_path)
#     img = tf.image.decode_jpeg(img, channels=3)
#     img = tf.cast(img, tf.float32) / 255.0
#     img = tf.expand_dims(img, axis=0)

#     preds = model.predict(img)
#     class_id = np.argmax(preds[0])
#     confidence = preds[0][class_id]

#     if confidence < threshold:
#         return "ì¼ë°˜ì“°ë ˆê¸°"
#     else:
#         return classes[class_id]

def classify_image(model, image_path, classes, threshold=0.5):
    """
    í•™ìŠµìš© ì½”ë“œ(ì˜µì…˜1) ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „í•˜ê²Œ ì´ë¯¸ì§€ ë¶„ë¥˜
    Args:
        model: í•™ìŠµëœ Keras ëª¨ë¸
        image_path: ë¶„ë¥˜í•  ì´ë¯¸ì§€ ê²½ë¡œ
        classes: í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸
        threshold: confidence ì„ê³„ê°’
    Returns:
        class_name ë˜ëŠ” "ì¼ë°˜ì“°ë ˆê¸°"
    """
    # ì´ë¯¸ì§€ ì½ê¸° ë° ë””ì½”ë”© (JPEG, PNG ëª¨ë‘ ê°€ëŠ¥)
    img = tf.io.read_file(image_path)
    img = tf.image.decode_image(img, channels=3)
    
    # í•™ìŠµìš© ì½”ë“œ ê¸°ì¤€: ì´ë¯¸ 224x224ì´ë¯€ë¡œ resize ë¶ˆí•„ìš”
    img.set_shape([224, 224, 3])
    
    # ì •ê·œí™”
    img = tf.cast(img, tf.float32) / 255.0
    
    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    img = tf.expand_dims(img, axis=0)
    
    # ì˜ˆì¸¡
    preds = model.predict(img)
    class_id = np.argmax(preds[0])
    confidence = preds[0][class_id]
    
    # threshold ê¸°ì¤€ íŒì •
    if confidence < threshold:
        return "ì¼ë°˜ì“°ë ˆê¸°"
    else:
        return classes[class_id], float(confidence)

# ì˜ˆì‹œ
# result = classify_image(model, "sample.jpg")
# print("ë¶„ë¥˜ ê²°ê³¼:", result)
